{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Bridge Pledge Score Computation**\n",
        "\n",
        "```{admonition} Overview\n",
        ":class: tip\n",
        "\n",
        "This notebook integrates all preprocessed metrics (Sources A–F, M, N, P) to compute each Member's **Bridge Pledge** score—a composite measure of bipartisan collaboration across sponsorships, communications, district lean, and ideology.  \n",
        "\n",
        "The final score combines standardized (0–100) values from each source, weighted according to our methodology, along with attendance and caucus‐membership bonuses. This notebook serves as a comprehensive demonstration of the complete Bridge Grades calculation process.\n",
        "\n",
        "For full methodology, definitions, and source details, see the Bridge Grades framework on our website: https://bridgegrades.org/methodology\n",
        "```\n",
        "\n",
        "## **Data Sources**\n",
        "\n",
        "### **Input Files**\n",
        "All processed data sources from previous notebooks:\n",
        "\n",
        "- **`119th_Congress_20250809.csv`** - Master congressional roster with bioguide IDs, states, districts, parties, and chambers\n",
        "- **`bridge_grade_source_a_cross_party_supported_bills.csv`** - Source A: Authors of bills with cross-party sponsors\n",
        "- **`bridge_grade_source_b_cross_party_cosponsors.csv`** - Source B: Cosponsors of cross-party bills\n",
        "- **`bridge_grades_source_cdef_app_communication.csv`** - Source C/D/E/F: APP communications data (bipartisanship and personal attacks)\n",
        "- **`bridge_grade_source_m_house_pvi.csv`** - Source M: Cook Political PVI for House districts\n",
        "- **`bridge_grade_source_m_senate_pvi.csv`** - Source M: Cook Political PVI for Senate states\n",
        "- **`bridge_grade_source_n_house_ideology.csv`** - Source N: VoteView ideological scores (House)\n",
        "- **`bridge_grade_source_n_senate_ideology.csv`** - Source N: VoteView ideological scores (Senate)\n",
        "- **`problem_solvers.csv`** - Source P: Problem Solvers Caucus membership\n",
        "- **`profiles.csv`** - Attendance data for filtering\n",
        "\n",
        "### **Output Files**\n",
        "- **`house_scores_119.xlsx`** - Complete House member scores and grades\n",
        "- **`senate_scores_119.xlsx`** - Complete Senate member scores and grades\n",
        "- **`congress_scores_119_*.xlsx`** - Combined datasets in various formats\n",
        "\n",
        "---\n",
        "\n",
        "## **Main Functions**\n",
        "\n",
        "### **1. Configuration and Setup**\n",
        "**Purpose:** Sets up scoring parameters and loads all data sources\n",
        "\n",
        "**Key Parameters:**\n",
        "- `att_pct = 0.2` - Minimum attendance threshold (20%) for grading eligibility\n",
        "- `weights` - Configurable weights for each data source (A=3, B=2, C=1, D=1, E=1, F=1)\n",
        "- `bonuses` - Scaling factors for PVI, ideology, and caucus bonuses\n",
        "\n",
        "### **2. Data Source Integration**\n",
        "**Purpose:** Merges all processed data sources into master datasets\n",
        "\n",
        "**For Each Source (A through F):**\n",
        "- Loads processed CSV file\n",
        "- Merges with master dataset using bioguide_id\n",
        "- Fills missing values appropriately (0 for counts, mean for percentages)\n",
        "- Calculates normalized scores using normal distribution CDF\n",
        "- Renames columns with source prefix for clarity\n",
        "\n",
        "### **3. Final Score Calculation**\n",
        "**Purpose:** Combines all normalized scores using weighted algorithm\n",
        "\n",
        "**Algorithm:**\n",
        "1. **Base Score (T_score):** Weighted sum of normalized source scores (A-F)\n",
        "2. **PVI Bonus (M_bonus):** Additional points for bridging in highly partisan districts\n",
        "3. **Ideology Bonus (N_bonus):** Additional points for bridging by non-centrist legislators\n",
        "4. **Caucus Bonus (P_bonus):** Fixed bonus for Problem Solvers Caucus members\n",
        "5. **Final Score (U_score):** T_score + M_bonus + N_bonus + P_bonus\n",
        "6. **Normalized Score (Bridge_Score):** CDF normalization of U_score (0-100)\n",
        "7. **Letter Grade (Bridge_Grade):** Statistical assignment (A/B/C/F) based on score distribution\n",
        "\n",
        "---\n",
        "\n",
        "## **Technical Requirements**\n",
        "\n",
        "### **Dependencies**\n",
        "- **pandas** - Data manipulation and analysis\n",
        "- **numpy** - Numerical operations\n",
        "- **scipy.stats** - Statistical functions (normal distribution CDF)\n",
        "- **seaborn** - Data visualization\n",
        "- **matplotlib.pyplot** - Plotting\n",
        "\n",
        "### **Data Processing Notes**\n",
        "- **Missing Value Handling:** Fills missing values with 0 for counts, column mean for percentages\n",
        "- **Duplicate Removal:** Removes duplicate bioguide_id entries\n",
        "- **Data Type Conversion:** Converts numeric columns to appropriate types for export\n",
        "- **Chamber Separation:** Processes House and Senate separately due to different data structures\n",
        "\n",
        "---\n",
        "\n",
        "## **Data Quality**\n",
        "\n",
        "### **Validation Checks**\n",
        "- **Attendance Filtering:** Removes members below 20% attendance threshold\n",
        "- **Duplicate Handling:** Removes duplicate bioguide_id entries\n",
        "- **Missing Data:** Appropriate filling strategies for each data type\n",
        "- **Score Validation:** Ensures all scores are within expected ranges\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Configuration & File Existence Checks**\n",
        "\n",
        "In this section we verify that all input files exist before proceeding, and validate that our `weights` dictionary matches the set of loaded source labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Global parameters\n",
        "att_pct   = 0.2   # Minimum attendance proportion\n",
        "weights   = {\n",
        "    'A': 3,   # Source A: num_bills_with_cross_party_cosponsors\n",
        "    'B': 2,   # Source B: num_cross_party_cosponsored_bills\n",
        "    'C': 1,   # Source C: communications that support members of the opposite party\n",
        "    'D': 1,   # Source D: proportion of communications that support members of the opposite party\n",
        "    'E': 1,   # Source E: communications classified as personal attacks\n",
        "    'F': 1,   # Source F: proportion of communications classified as personal attacks\n",
        "}\n",
        "\n",
        "bonuses = {\n",
        "    'pvi_value_cap': 15, # number of PVI points to cap at\n",
        "    'max_P_bonus_scaling_factor': 0.01, # scaling factor for P bonus\n",
        "    'max_N_bonus_scaling_factor': 0.05, # scaling factor for N bonus\n",
        "    'max_M_bonus_scaling_factor': 0.38 # scaling factor for M bonus\n",
        "}\n",
        "\n",
        "# Define all required file paths\n",
        "BASE_DIR = '../Data' # Uncomment this line if running locally\n",
        "paths = {\n",
        "    'meta':        f\"{BASE_DIR}/Source C-D-E-F/Input files/119th_Congress_20250809.csv\",\n",
        "    'A':           f\"{BASE_DIR}/Source A-B/Output files/bridge_grade_source_a_cross_party_supported_bills.csv\",\n",
        "    'B':           f\"{BASE_DIR}/Source A-B/Output files/bridge_grade_source_b_cross_party_cosponsors.csv\",\n",
        "    'CDEF':        f\"{BASE_DIR}/Source C-D-E-F/Output files/bridge_grades_source_cdef_app_communication.csv\",\n",
        "    'M_House':     f\"{BASE_DIR}/Source M/Output files/bridge_grade_source_m_house_pvi.csv\",\n",
        "    'M_Senate':    f\"{BASE_DIR}/Source M/Output files/bridge_grade_source_m_senate_pvi.csv\",\n",
        "    'N_House':     f\"{BASE_DIR}/Source N/Output files/bridge_grade_source_n_house_ideology.csv\",\n",
        "    'N_Senate':    f\"{BASE_DIR}/Source N/Output files/bridge_grade_source_n_senate_ideology.csv\",\n",
        "    'P':           f\"{BASE_DIR}/Source P/problem_solvers.csv\",\n",
        "}\n",
        "\n",
        "# Load raw APP profiles (attendance data)\n",
        "source_APP_profiles = pd.read_csv(\n",
        "    f\"{BASE_DIR}/profiles.csv\",\n",
        "    usecols=['full_name','bioguide_id','attendance_total','attendance_max']\n",
        ")\n",
        "\n",
        "# Check each file exists\n",
        "missing_files = [key for key, p in paths.items() if not os.path.exists(p)]\n",
        "if missing_files:\n",
        "    raise FileNotFoundError(f\"Missing input files for sources: {missing_files}\")\n",
        "print(\"All input files found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Load DataFrames & Validate Weights**\n",
        "\n",
        "We load each CSV into a DataFrame and then ensure the set of weight keys matches the loaded source labels exactly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load master metadata\n",
        "meta_data        = pd.read_csv(paths['meta'])\n",
        "\n",
        "# Load each source DataFrame\n",
        "source_A         = pd.read_csv(paths['A'])\n",
        "source_B         = pd.read_csv(paths['B'])\n",
        "source_APP       = pd.read_csv(paths['CDEF'])\n",
        "source_M_House   = pd.read_csv(paths['M_House'])\n",
        "source_M_Senate  = pd.read_csv(paths['M_Senate'])\n",
        "source_N_House   = pd.read_csv(paths['N_House'])\n",
        "source_N_Senate  = pd.read_csv(paths['N_Senate'])\n",
        "source_P         = pd.read_csv(paths['P'])\n",
        "\n",
        "# Verify weight keys vs. sources to be scored (A–F)\n",
        "loaded_sources = set(weights.keys())\n",
        "expected_sources = {'A','B','C','D','E','F'}\n",
        "if loaded_sources != expected_sources:\n",
        "    raise ValueError(\n",
        "        f\"Weights keys {loaded_sources} do not match expected {expected_sources}\"\n",
        "    )\n",
        "\n",
        "print(\"Weights validated against source labels.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Build Base Member Tables**\n",
        "\n",
        "In this section we initialize our working DataFrames for the House and Senate by subsetting the master `meta_data`. These tables will be the foundation for merging each source's metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preview master metadata\n",
        "meta_data.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Subset to House members\n",
        "house_final = meta_data.query(\"Chamber=='House'\").copy()\n",
        "print(f\"House members: {house_final.shape[0]}\")\n",
        "house_final.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Subset to Senate members\n",
        "senate_final = meta_data.query(\"Chamber=='Senate'\").copy()\n",
        "print(f\"Senate members: {senate_final.shape[0]}\")\n",
        "senate_final.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Attendance Filtering**\n",
        "\n",
        "Legislators below the minimum attendance threshold (`att_pct`) are excluded from scoring. We calculate each member's attendance percentage and remove those below `att_pct`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract attendance data\n",
        "source_att = source_APP_profiles[[\n",
        "    'full_name','bioguide_id','attendance_total','attendance_max'\n",
        "]].copy()\n",
        "source_att.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing attendance data\n",
        "missing_attendance = source_att[source_att['attendance_total'].isna()]\n",
        "print(f\"Legislators with missing attendance data: {len(missing_attendance)}\")\n",
        "print(\"Note: Missing legislators are typically non-voting members from territories.\")\n",
        "missing_attendance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill missing totals with zero\n",
        "source_att['attendance_total'] = source_att['attendance_total'].fillna(0)\n",
        "\n",
        "# Compute attendance percentage\n",
        "source_att['attendance_pct'] = (\n",
        "    source_att['attendance_total'] / source_att['attendance_max']\n",
        ")\n",
        "\n",
        "# Identify members below threshold\n",
        "low_att = source_att.query(\"attendance_pct < @att_pct\").drop_duplicates(subset='bioguide_id')\n",
        "print(f\"Legislators below {att_pct*100}% attendance threshold: {len(low_att)}\")\n",
        "print(\"Note: All legislators with low attendance are non-voting members from territories.\")\n",
        "low_att\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove low‐attendance members from both tables\n",
        "to_remove = set(low_att['bioguide_id'])\n",
        "house_final = house_final[~house_final['bioguide_id'].isin(to_remove)].copy()\n",
        "senate_final = senate_final[~senate_final['bioguide_id'].isin(to_remove)].copy()\n",
        "\n",
        "print(f\"Final House members: {house_final.shape[0]}\")\n",
        "print(f\"Final Senate members: {senate_final.shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Data Source Processing**\n",
        "\n",
        "This section processes each data source (A through F) by merging the data with our master datasets and calculating normalized scores. Each source is processed separately for House and Senate members.\n",
        "\n",
        "### **Source A: Authors of Bills with Cross-Party Sponsors**\n",
        "\n",
        "Rewards Members of the 119th U.S. Congress for sponsoring legislation that attracted at least one cosponsor from the opposite party. We take each legislator's total count of such bills, fill true \"no-activity\" values with zeros, and convert counts into a 0–100 percentile score.\n",
        "\n",
        "- **Data origin:** OpenStates bill sponsorship CSV for the 119th Congress  \n",
        "- **Download link:** https://open.pluralpolicy.com/data/session-csv/  \n",
        "- **Date downloaded:** August 8, 2025  \n",
        "- **Preprocessing notebook:** \"Source A – B: Legislator and Sponsorship Data\"  \n",
        "\n",
        "> **Why fill with zeros?**  \n",
        "> A missing count indicates the legislator had **no** cross-party bills. Zero appropriately reflects \"no activity,\" not unknown data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select only the primary bioguide ID and cross-party bill count\n",
        "source_A = source_A[['primary_bioguide_id', 'num_bills_with_cross_party_cosponsors']].copy()\n",
        "assert {'primary_bioguide_id','num_bills_with_cross_party_cosponsors'} <= set(source_A.columns), \\\n",
        "    \"Unexpected columns in source_A\"\n",
        "source_A.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge into house_final by bioguide_id\n",
        "house_final = house_final.merge(\n",
        "    source_A.rename(columns={'primary_bioguide_id':'bioguide_id'}),\n",
        "    on='bioguide_id',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Check for missing values\n",
        "missing_house = house_final[house_final['num_bills_with_cross_party_cosponsors'].isna()]\n",
        "print(f\"House members with missing Source A data: {len(missing_house)}\")\n",
        "print(\"Note: Missing values typically indicate no cross-party bill sponsorship activity.\")\n",
        "missing_house[['Name', 'Party', 'State']].head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill missing counts (no cross-party bills) with zero\n",
        "house_final['num_bills_with_cross_party_cosponsors'] = house_final[\n",
        "    'num_bills_with_cross_party_cosponsors'\n",
        "].fillna(0)\n",
        "\n",
        "# Normalize A House\n",
        "house_final['A: num_bills_with_cross_party_cosponsors'] = \\\n",
        "    house_final['num_bills_with_cross_party_cosponsors']\n",
        "\n",
        "# Calculate mean and std for normalization\n",
        "mean_A = house_final['num_bills_with_cross_party_cosponsors'].mean()\n",
        "std_A = house_final['num_bills_with_cross_party_cosponsors'].std()\n",
        "\n",
        "# Add normalized column using CDF\n",
        "house_final['A_norm'] = norm.cdf(house_final['num_bills_with_cross_party_cosponsors'], mean_A, std_A) * 100\n",
        "\n",
        "# Add weight column\n",
        "house_final['A_weight'] = weights['A']\n",
        "\n",
        "# Clean up\n",
        "house_final.drop(columns=['num_bills_with_cross_party_cosponsors'], inplace=True)\n",
        "house_final.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge into senate_final by bioguide_id\n",
        "senate_final = senate_final.merge(\n",
        "    source_A.rename(columns={'primary_bioguide_id':'bioguide_id'}),\n",
        "    on='bioguide_id',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Check for missing values\n",
        "missing_senate = senate_final[senate_final['num_bills_with_cross_party_cosponsors'].isna()]\n",
        "print(f\"Senate members with missing Source A data: {len(missing_senate)}\")\n",
        "print(\"Note: No missing values in Senate data.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill missing counts with zero\n",
        "senate_final['num_bills_with_cross_party_cosponsors'] = senate_final[\n",
        "    'num_bills_with_cross_party_cosponsors'\n",
        "].fillna(0)\n",
        "\n",
        "# Normalize A - Senate\n",
        "senate_final['A: num_bills_with_cross_party_cosponsors'] = \\\n",
        "    senate_final['num_bills_with_cross_party_cosponsors']\n",
        "\n",
        "# Calculate mean and std for normalization\n",
        "mean_A = senate_final['num_bills_with_cross_party_cosponsors'].mean()\n",
        "std_A = senate_final['num_bills_with_cross_party_cosponsors'].std()\n",
        "\n",
        "# Add normalized column using CDF\n",
        "senate_final['A_norm'] = norm.cdf(senate_final['num_bills_with_cross_party_cosponsors'], mean_A, std_A) * 100\n",
        "\n",
        "# Add weight column\n",
        "senate_final['A_weight'] = weights['A']\n",
        "\n",
        "# Drop duplicates and cleanup\n",
        "senate_final.drop_duplicates(subset='bioguide_id', inplace=True)\n",
        "senate_final.drop(columns=['num_bills_with_cross_party_cosponsors'], inplace=True)\n",
        "senate_final.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Source B: Cosponsors of Cross-Party Bills**\n",
        "\n",
        "This section processes **Source B**, which rewards Members of the 119th U.S. Congress for **cosponsoring** bills authored by another party. We take each legislator's total count of such cross-party cosponsorships, fill true zero-activity values with zeros, and convert counts into a 0–100 percentile score.\n",
        "\n",
        "- **Data origin:** OpenStates bill sponsorship CSV for the 119th Congress  \n",
        "- **Download link:** https://open.pluralpolicy.com/data/session-csv/  \n",
        "- **Date downloaded:** August 8, 2025  \n",
        "- **Preprocessing notebook:** \"Source A – B: Legislator and Sponsorship Data\"  \n",
        "\n",
        "> **Why fill with zeros?**  \n",
        "> A missing count indicates the legislator did **not** cosponsor any cross-party bills. Zero correctly represents \"no activity.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select only bioguide_id and cosponsor count\n",
        "assert {'bioguide_id','num_cross_party_cosponsored_bills'} <= set(source_B.columns), \\\n",
        "    \"Unexpected columns in source_B\"\n",
        "source_B = source_B[['bioguide_id','num_cross_party_cosponsored_bills']].copy()\n",
        "source_B.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge into house_final by bioguide_id\n",
        "house_final = house_final.merge(\n",
        "    source_B,\n",
        "    on='bioguide_id',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Check for missing values\n",
        "missing_house = house_final[house_final['num_cross_party_cosponsored_bills'].isna()]\n",
        "print(f\"House members with missing Source B data: {len(missing_house)}\")\n",
        "print(\"Note: No missing values for the house.\")\n",
        "\n",
        "# Fill missing counts with zero\n",
        "house_final['num_cross_party_cosponsored_bills'] = \\\n",
        "    house_final['num_cross_party_cosponsored_bills'].fillna(0)\n",
        "\n",
        "# Normalize B - House\n",
        "house_final['B: num_cross_party_cosponsored_bills'] = \\\n",
        "    house_final['num_cross_party_cosponsored_bills']\n",
        "\n",
        "# Calculate mean and std for normalization\n",
        "mean_B = house_final['num_cross_party_cosponsored_bills'].mean()\n",
        "std_B = house_final['num_cross_party_cosponsored_bills'].std()\n",
        "\n",
        "# Add normalized column using CDF\n",
        "house_final['B_norm'] = norm.cdf(house_final['num_cross_party_cosponsored_bills'], mean_B, std_B) * 100\n",
        "\n",
        "# Add weight column\n",
        "house_final['B_weight'] = weights['B']\n",
        "\n",
        "# Clean up raw column\n",
        "house_final.drop(columns=['num_cross_party_cosponsored_bills'], inplace=True)\n",
        "house_final.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge into senate_final by bioguide_id\n",
        "senate_final = senate_final.merge(\n",
        "    source_B,\n",
        "    on='bioguide_id',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Check for missing values\n",
        "missing_senate = senate_final[senate_final['num_cross_party_cosponsored_bills'].isna()]\n",
        "print(f\"Senate members with missing Source B data: {len(missing_senate)}\")\n",
        "print(\"Note: No missing values for the Senate.\")\n",
        "\n",
        "# Fill missing counts with zero\n",
        "senate_final['num_cross_party_cosponsored_bills'] = \\\n",
        "    senate_final['num_cross_party_cosponsored_bills'].fillna(0)\n",
        "\n",
        "# Normalize B - Senate\n",
        "senate_final['B: num_cross_party_cosponsored_bills'] = \\\n",
        "    senate_final['num_cross_party_cosponsored_bills']\n",
        "\n",
        "# Calculate mean and std for normalization\n",
        "mean_B = senate_final['num_cross_party_cosponsored_bills'].mean()\n",
        "std_B = senate_final['num_cross_party_cosponsored_bills'].std()\n",
        "\n",
        "# Add normalized column using CDF\n",
        "senate_final['B_norm'] = norm.cdf(senate_final['num_cross_party_cosponsored_bills'], mean_B, std_B) * 100\n",
        "\n",
        "# Add weight column\n",
        "senate_final['B_weight'] = weights['B']\n",
        "\n",
        "# Drop duplicate legislators and cleanup\n",
        "senate_final.drop_duplicates(subset='bioguide_id', inplace=True)\n",
        "senate_final.drop(columns=['num_cross_party_cosponsored_bills'], inplace=True)\n",
        "senate_final.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Sources C, D, E, F: Communication Analysis**\n",
        "\n",
        "These sources analyze public communication patterns of legislators to measure bipartisanship and divisiveness in their rhetoric.\n",
        "\n",
        "#### **Source C: Bipartisan Communication (Sum)**\n",
        "Rewards Members for communications that support members of the opposite party. We count each legislator's total **outcome_bipartisanship** flags and convert counts into a 0–100 percentile score.\n",
        "\n",
        "#### **Source D: Bipartisan Communication (Percentage)**\n",
        "Rewards Members for the **proportion** of their communications that are supportive of the opposite party. We take each legislator's percentage and convert it into a percentile score.\n",
        "\n",
        "#### **Source E: Personal Attacks (Sum)**\n",
        "Penalizes Members for communications classified as personal attacks. We count each legislator's total **attack_personal** flags and convert into an **inverse** normalized score—higher attack counts yield lower scores.\n",
        "\n",
        "#### **Source F: Personal Attacks (Percentage)**\n",
        "Penalizes Members based on the **percentage** of their communications that are personal attacks. Higher attack rates → lower scores.\n",
        "\n",
        "- **Data origin:** American Political Pulse communications CSV (2025 download)  \n",
        "- **Download link:** https://americaspoliticalpulse.com/data/ (Download \"US officials – 2025\")  \n",
        "- **Date downloaded:** August 8, 2025  \n",
        "- **Preprocessing notebook:** *Source C–D–E–F: App_Communications_Calculations*  \n",
        "\n",
        "> **Why fill with zeros?**  \n",
        "> Missing values indicate no activity in that category. Zero accurately represents \"none.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process Source C: Bipartisan Communication (Sum)\n",
        "assert 'outcome_bipartisanship' in source_APP.columns, \"Missing 'outcome_bipartisanship' in source_APP\"\n",
        "source_C = source_APP[['bioguide_id','outcome_bipartisanship']].copy()\n",
        "\n",
        "# Merge into house_final\n",
        "house_final = house_final.merge(source_C, on='bioguide_id', how='left')\n",
        "house_final['outcome_bipartisanship'] = house_final['outcome_bipartisanship'].fillna(0)\n",
        "\n",
        "# Normalize C - House\n",
        "house_final['C: outcome_bipartisanship'] = house_final['outcome_bipartisanship']\n",
        "mean_C = house_final['outcome_bipartisanship'].mean()\n",
        "std_C = house_final['outcome_bipartisanship'].std()\n",
        "house_final['C_norm'] = norm.cdf(house_final['outcome_bipartisanship'], mean_C, std_C) * 100\n",
        "house_final['C_weight'] = weights['C']\n",
        "house_final.drop(columns=['outcome_bipartisanship'], inplace=True)\n",
        "\n",
        "# Merge into senate_final\n",
        "senate_final = senate_final.merge(source_C, on='bioguide_id', how='left')\n",
        "senate_final['outcome_bipartisanship'] = senate_final['outcome_bipartisanship'].fillna(0)\n",
        "\n",
        "# Normalize C - Senate\n",
        "senate_final['C: outcome_bipartisanship'] = senate_final['outcome_bipartisanship']\n",
        "mean_C = senate_final['outcome_bipartisanship'].mean()\n",
        "std_C = senate_final['outcome_bipartisanship'].std()\n",
        "senate_final['C_norm'] = norm.cdf(senate_final['outcome_bipartisanship'], mean_C, std_C) * 100\n",
        "senate_final['C_weight'] = weights['C']\n",
        "senate_final.drop(columns=['outcome_bipartisanship'], inplace=True)\n",
        "\n",
        "print(\"Source C processing completed for both chambers.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process Source D: Bipartisan Communication (Percentage)\n",
        "assert 'outcome_bipartisanship_pct' in source_APP.columns, \"Missing 'outcome_bipartisanship_pct' in source_APP\"\n",
        "source_D = source_APP[['bioguide_id','outcome_bipartisanship_pct']].copy()\n",
        "\n",
        "# Merge into house_final\n",
        "house_final = house_final.merge(source_D, on='bioguide_id', how='left')\n",
        "house_final['outcome_bipartisanship_pct'] = house_final['outcome_bipartisanship_pct'].fillna(0)\n",
        "\n",
        "# Normalize D - House\n",
        "house_final['D: outcome_bipartisanship_pct'] = house_final['outcome_bipartisanship_pct']\n",
        "mean_D = house_final['outcome_bipartisanship_pct'].mean()\n",
        "std_D = house_final['outcome_bipartisanship_pct'].std()\n",
        "house_final['D_norm'] = norm.cdf(house_final['outcome_bipartisanship_pct'], mean_D, std_D) * 100\n",
        "house_final['D_weight'] = weights['D']\n",
        "house_final.drop(columns=['outcome_bipartisanship_pct'], inplace=True)\n",
        "\n",
        "# Merge into senate_final\n",
        "senate_final = senate_final.merge(source_D, on='bioguide_id', how='left')\n",
        "senate_final['outcome_bipartisanship_pct'] = senate_final['outcome_bipartisanship_pct'].fillna(0)\n",
        "\n",
        "# Normalize D - Senate\n",
        "senate_final['D: outcome_bipartisanship_pct'] = senate_final['outcome_bipartisanship_pct']\n",
        "mean_D = senate_final['outcome_bipartisanship_pct'].mean()\n",
        "std_D = senate_final['outcome_bipartisanship_pct'].std()\n",
        "senate_final['D_norm'] = norm.cdf(senate_final['outcome_bipartisanship_pct'], mean_D, std_D) * 100\n",
        "senate_final['D_weight'] = weights['D']\n",
        "senate_final.drop(columns=['outcome_bipartisanship_pct'], inplace=True)\n",
        "\n",
        "print(\"Source D processing completed for both chambers.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process Source E: Personal Attacks (Sum) - INVERSE SCORING\n",
        "assert 'attack_personal' in source_APP.columns, \"Missing 'attack_personal' in source_APP\"\n",
        "source_E = source_APP[['bioguide_id','attack_personal']].copy()\n",
        "\n",
        "# Merge into house_final\n",
        "house_final = house_final.merge(source_E, on='bioguide_id', how='left')\n",
        "house_final['attack_personal'] = house_final['attack_personal'].fillna(0)\n",
        "\n",
        "# Normalize E - House (INVERSE: more attacks = lower score)\n",
        "house_final['E: attack_personal'] = house_final['attack_personal']\n",
        "mean_E = house_final['attack_personal'].mean()\n",
        "std_E = house_final['attack_personal'].std()\n",
        "house_final['E_norm'] = 1 - (norm.cdf(house_final['attack_personal'], mean_E, std_E) * 100)\n",
        "house_final['E_weight'] = weights['E']\n",
        "house_final.drop(columns=['attack_personal'], inplace=True)\n",
        "\n",
        "# Merge into senate_final\n",
        "senate_final = senate_final.merge(source_E, on='bioguide_id', how='left')\n",
        "senate_final['attack_personal'] = senate_final['attack_personal'].fillna(0)\n",
        "\n",
        "# Normalize E - Senate (INVERSE: more attacks = lower score)\n",
        "senate_final['E: attack_personal'] = senate_final['attack_personal']\n",
        "mean_E = senate_final['attack_personal'].mean()\n",
        "std_E = senate_final['attack_personal'].std()\n",
        "senate_final['E_norm'] = 1 - (norm.cdf(senate_final['attack_personal'], mean_E, std_E) * 100)\n",
        "senate_final['E_weight'] = weights['E']\n",
        "senate_final.drop(columns=['attack_personal'], inplace=True)\n",
        "\n",
        "print(\"Source E processing completed for both chambers.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process Source F: Personal Attacks (Percentage) - INVERSE SCORING\n",
        "assert 'attack_personal_pct' in source_APP.columns, \"Missing 'attack_personal_pct' in source_APP\"\n",
        "source_F = source_APP[['bioguide_id','attack_personal_pct']].copy()\n",
        "\n",
        "# Merge into house_final\n",
        "house_final = house_final.merge(source_F, on='bioguide_id', how='left')\n",
        "house_final['attack_personal_pct'] = house_final['attack_personal_pct'].fillna(0)\n",
        "\n",
        "# Normalize F - House (INVERSE: more attacks = lower score)\n",
        "house_final['F: attack_personal_pct'] = house_final['attack_personal_pct']\n",
        "mean_F = house_final['attack_personal_pct'].mean()\n",
        "std_F = house_final['attack_personal_pct'].std()\n",
        "house_final['F_norm'] = 1 - (norm.cdf(house_final['attack_personal_pct'], mean_F, std_F) * 100)\n",
        "house_final['F_weight'] = weights['F']\n",
        "house_final.drop(columns=['attack_personal_pct'], inplace=True)\n",
        "\n",
        "# Merge into senate_final\n",
        "senate_final = senate_final.merge(source_F, on='bioguide_id', how='left')\n",
        "senate_final['attack_personal_pct'] = senate_final['attack_personal_pct'].fillna(0)\n",
        "\n",
        "# Normalize F - Senate (INVERSE: more attacks = lower score)\n",
        "senate_final['F: attack_personal_pct'] = senate_final['attack_personal_pct']\n",
        "mean_F = senate_final['attack_personal_pct'].mean()\n",
        "std_F = senate_final['attack_personal_pct'].std()\n",
        "senate_final['F_norm'] = 1 - (norm.cdf(senate_final['attack_personal_pct'], mean_F, std_F) * 100)\n",
        "senate_final['F_weight'] = weights['F']\n",
        "senate_final.drop(columns=['attack_personal_pct'], inplace=True)\n",
        "\n",
        "print(\"Source F processing completed for both chambers.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Bonus Sources (M, N, P)**\n",
        "\n",
        "These sources provide additional context and bonuses to the base scoring system.\n",
        "\n",
        "### **Source M: Cook Political Partisan Voting Index (PVI)**\n",
        "\n",
        "This section processes **Source M**, which captures each district's partisan lean (Cook PVI) for the 119th Congress. A **higher** PVI number means a stronger lean toward one party; a **lower** PVI indicates a more competitive (centrist) district. We cap the PVI value at 15.\n",
        "\n",
        "- **Data origin:** Cook Political PVI via subscription at cookpolitical.com  \n",
        "- **Date downloaded:** April, 2025 (this data is updated periodically, not daily, last checked August 8, 2025)  \n",
        "- **Preprocessing notebook:** *Source M House & Senate Cook Political PVI*\n",
        "\n",
        "### **Source N: VoteView Member Ideology Score**\n",
        "\n",
        "This section merges pre-computed ideology percentiles into the Bridge Pledge tables. The percentiles measure how far each legislator lies from the partisan center, rewarding those closer to the middle.\n",
        "\n",
        "- **Data source:** Voteview \"Member Ideology\" CSV exports (House and Senate, 119th Congress)  \n",
        "- **Date downloaded:** August 8, 2025  \n",
        "- **Preprocessing notebook:** *Source N: VoteView Member Ideology Scores.ipynb*\n",
        "\n",
        "### **Source P: Problem Solvers Caucus \"Bump\"**\n",
        "\n",
        "This section applies a fixed points boost to members of the Problem Solvers Caucus (PSC). We load the externally maintained list of PSC bioguide IDs, flag each legislator, and add the configured bonus to their pledge score.\n",
        "\n",
        "- **Data source:** `problem_solvers.csv` (one column: `bioguide_id`), maintained in our data repo. Source: https://problemsolverscaucus.house.gov/caucus-members\n",
        "- **Date Updated:** July 20, 2025\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process Source M: Cook Political PVI\n",
        "# House PVI\n",
        "pvi_cols = [c for c in source_M_House.columns if \"PVI_Number\" in c]\n",
        "assert pvi_cols, f\"No PVI number column found in source_M_House: {source_M_House.columns.tolist()}\"\n",
        "pvi_col = pvi_cols[0]\n",
        "\n",
        "source_M_h = source_M_House[['bioguide_id', pvi_col]].copy()\n",
        "source_M_h.rename(columns={pvi_col: 'M: Cook PVI Raw'}, inplace=True)\n",
        "\n",
        "# Cap PVI values\n",
        "pvi_value_cap = bonuses['pvi_value_cap']\n",
        "source_M_h['M_Cook_PVI_Cap'] = source_M_h['M: Cook PVI Raw'].apply(lambda x: pvi_value_cap if x > pvi_value_cap else x)\n",
        "\n",
        "# Merge into house_final\n",
        "house_final = house_final.merge(source_M_h, on='bioguide_id', how='left')\n",
        "\n",
        "# Senate PVI\n",
        "pvi_cols_s = [c for c in source_M_Senate.columns if \"PVI_Number\" in c]\n",
        "assert pvi_cols_s, f\"No PVI number column found in source_M_Senate: {source_M_Senate.columns.tolist()}\"\n",
        "pvi_col_s = pvi_cols_s[0]\n",
        "\n",
        "source_M_s = source_M_Senate[['bioguide_id', pvi_col_s]].copy()\n",
        "source_M_s.rename(columns={pvi_col_s: 'M: Cook PVI Raw'}, inplace=True)\n",
        "\n",
        "# Cap PVI values\n",
        "source_M_s['M_Cook_PVI_Cap'] = source_M_s['M: Cook PVI Raw'].apply(lambda x: pvi_value_cap if x > pvi_value_cap else x)\n",
        "\n",
        "# Merge into senate_final\n",
        "senate_final = senate_final.merge(source_M_s, on='bioguide_id', how='left')\n",
        "\n",
        "print(\"Source M (PVI) processing completed for both chambers.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process Source N: VoteView Ideology Scores\n",
        "# Rename columns for consistency\n",
        "source_N_House.rename(columns={'nominate_dim1': 'N: nominate_dim1', 'ideology_dist': 'N_ideology_dist'}, inplace=True)\n",
        "source_N_Senate.rename(columns={'nominate_dim1': 'N: nominate_dim1', 'ideology_dist': 'N_ideology_dist'}, inplace=True)\n",
        "\n",
        "# Merge into house_final\n",
        "house_final = house_final.merge(\n",
        "    source_N_House[['bioguide_id', 'N: nominate_dim1', 'N_ideology_dist']],\n",
        "    on='bioguide_id',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Merge into senate_final\n",
        "senate_final = senate_final.merge(\n",
        "    source_N_Senate[['bioguide_id', 'N: nominate_dim1', 'N_ideology_dist']],\n",
        "    on='bioguide_id',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "print(\"Source N (Ideology) processing completed for both chambers.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process Source P: Problem Solvers Caucus\n",
        "# Load the external CSV of caucus members\n",
        "psc_ids = set(\n",
        "    pd.read_csv(\n",
        "        '../Data/Source P/problem_solvers.csv'\n",
        "    )['bioguide_id']\n",
        ")\n",
        "\n",
        "def apply_psc_bump(df, id_col='bioguide_id'):\n",
        "    \"\"\"\n",
        "    Add PSC bump:\n",
        "      - P_flag: 1 if member is in PSC, else 0\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    df['P_flag'] = df[id_col].isin(psc_ids).astype(int)\n",
        "    return df\n",
        "\n",
        "# Check for any PSC IDs not present in the House roster\n",
        "missing_in_house = psc_ids - set(house_final['bioguide_id'])\n",
        "if missing_in_house:\n",
        "    print(f\"Warning: PSC IDs not in House table: {sorted(missing_in_house)}\")\n",
        "\n",
        "# Apply PSC bump to House\n",
        "house_final = apply_psc_bump(house_final)\n",
        "\n",
        "# Note: Only House members are included in the PSC, so this is not applicable to the Senate\n",
        "senate_final[\"P_flag\"] = 0\n",
        "\n",
        "print(\"Source P (Problem Solvers Caucus) processing completed for both chambers.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Final Score Calculation & Grade Assignment**\n",
        "\n",
        "In this final phase, we turn each legislator's normalized source scores into a composite Bridge Grade. We:\n",
        "\n",
        "1. **Combine** weighted normalized scores from each Source (`A`–`F`).  \n",
        "2. **Apply** multipliers (`M`, `N`, `P`) on top of the normalized, weighted score.    \n",
        "3. **Assign** a letter grade (`A`, `B`, `C`, `F`) based on statistical thresholds (mean ± std and the median).  \n",
        "4. **Normalize** the combined score to a 0–100 percentile.\n",
        "\n",
        "### **Scoring Algorithm**\n",
        "\n",
        "The `cal_score()` function:\n",
        "\n",
        "- **Aggregates** `norm_{X}` columns only if they exist in the DataFrame.\n",
        "- **Weights** Assigns the weights for each source.\n",
        "- **Adds** ideology multipliers (`M`, `N`, `P`) safely, with the following formulas:\n",
        "  - `bonus_m = [score_T*(1+M)*max_M_bonus_scaling_factor] - score_T`\n",
        "  - `bonus_n = score_T * max_N_bonus_scaling_factor * N_ideology_dist`\n",
        "  - `bonus_p = max_P_bonus_scaling_factor * score_T_max * P_flag`\n",
        "    where `score_T_max` is the max `score_T` across all legislators\n",
        "\n",
        "- `score_U = score_T + bonus_m + bonus_n + bonus_p`\n",
        "- **Normalizes** the total (`score_U`) via the Normal CDF.\n",
        "- **Assigns** letter grades using:  \n",
        "  - `A` if `score_U > mean + std`  \n",
        "  - `B` if `median < score_U ≤ mean + std`  \n",
        "  - `C` if `mean - std < score_U ≤ median`  \n",
        "  - `F` otherwise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cal_score(data, weights, bonuses):\n",
        "    \"\"\"\n",
        "    Calculate Bridge Pledge scores for legislators.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    data : pandas.DataFrame\n",
        "        DataFrame containing legislator data with normalized source scores\n",
        "    weights : dict\n",
        "        Dictionary mapping source letters to their weights\n",
        "    bonuses : dict\n",
        "        Dictionary containing bonus scaling factors\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    pandas.DataFrame\n",
        "        DataFrame with calculated scores and grades\n",
        "    \"\"\"\n",
        "    # Copy the data to avoid modifying the original dataframe\n",
        "    temp_data = data.copy()\n",
        "\n",
        "    # Initialize columns\n",
        "    temp_data['score_T'] = 0\n",
        "\n",
        "    # Calculate 'score_T' by adding weighted norm values for each category\n",
        "    for i in weights.keys():\n",
        "        temp_data['score_T'] += temp_data[f\"{i}_norm\"] * weights[i]\n",
        "\n",
        "    # Calculate bonuses\n",
        "    # PVI bonus (M)\n",
        "    temp_data['bonus_m'] = (temp_data['score_T']*(1+(temp_data['M_Cook_PVI_Cap']/100)*bonuses['max_M_bonus_scaling_factor']))-temp_data['score_T']\n",
        "\n",
        "    # Ideology bonus (N)\n",
        "    temp_data['bonus_n'] = temp_data['score_T'] * bonuses['max_N_bonus_scaling_factor'] * temp_data['N_ideology_dist']\n",
        "\n",
        "    # Ensure bonuses are non-negative\n",
        "    temp_data['bonus_m'] = temp_data['bonus_m'].clip(lower=0)\n",
        "    temp_data['bonus_n'] = temp_data['bonus_n'].clip(lower=0)\n",
        "\n",
        "    # Caucus bonus (P)\n",
        "    temp_data['bonus_p'] = np.ceil(\n",
        "      bonuses['max_P_bonus_scaling_factor']\n",
        "      * temp_data['score_T'].max()\n",
        "      * temp_data['P_flag']\n",
        "    ).astype(int)\n",
        "\n",
        "    # Final score\n",
        "    temp_data['score_U'] = temp_data['score_T'] + temp_data['bonus_m'] + temp_data['bonus_n'] + temp_data['bonus_p']\n",
        "\n",
        "    # Calculate statistics for grade assignment\n",
        "    mean_U = round(temp_data['score_U'].mean(), 2)\n",
        "    std_U = round(temp_data['score_U'].std(), 2)\n",
        "    median_U = round(temp_data['score_U'].median(), 2)\n",
        "\n",
        "    # Normalize 'score_U' using the cumulative distribution function (CDF)\n",
        "    temp_data['norm_U'] = norm.cdf(temp_data['score_U'], mean_U, std_U) * 100\n",
        "\n",
        "    # Define the grade assignment function based on the calculated scores\n",
        "    def assign_grade(grade):\n",
        "        if grade > mean_U + std_U:\n",
        "            return 'A'\n",
        "        elif grade > median_U:\n",
        "            return 'B'\n",
        "        elif grade > mean_U - std_U:\n",
        "            return 'C'\n",
        "        else:\n",
        "            return 'F'\n",
        "\n",
        "    # Apply the grade assignment to the 'score_U' column\n",
        "    temp_data['Grade'] = temp_data['score_U'].apply(assign_grade)\n",
        "\n",
        "    return temp_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate scores for House members\n",
        "house_final_test = cal_score(house_final, weights, bonuses)\n",
        "print(\"House scores calculated successfully.\")\n",
        "print(f\"House members processed: {len(house_final_test)}\")\n",
        "\n",
        "# Display grade distribution\n",
        "print(\"\\nHouse Grade Distribution:\")\n",
        "print(house_final_test['Grade'].value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate scores for Senate members\n",
        "senate_final_test = cal_score(senate_final, weights, bonuses)\n",
        "print(\"Senate scores calculated successfully.\")\n",
        "print(f\"Senate members processed: {len(senate_final_test)}\")\n",
        "\n",
        "# Display grade distribution\n",
        "print(\"\\nSenate Grade Distribution:\")\n",
        "print(senate_final_test['Grade'].value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Data Visualization**\n",
        "\n",
        "This section creates visualizations to show the distribution of Bridge Grades across both chambers and political parties.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create visualizations for grade distributions\n",
        "order = [\"A\", \"B\", \"C\", \"F\"]\n",
        "hue_order = ['Democratic', 'Republican', 'Independent']\n",
        "\n",
        "purple_palette = [\"#4B0082\", \"#5D3FD3\", \"#7B68EE\"]\n",
        "\n",
        "def plot_with_counts(data, title):\n",
        "    ax = sns.countplot(\n",
        "        x='Grade',\n",
        "        hue='Party',\n",
        "        data=data,\n",
        "        palette=purple_palette,\n",
        "        order=order,\n",
        "        hue_order=hue_order\n",
        "    )\n",
        "    ax.set_title(title)\n",
        "\n",
        "    # Calculate maximum height for y-axis scaling\n",
        "    max_height = max([p.get_height() for p in ax.patches])\n",
        "    ax.set_ylim(0, max_height * 1.15)  # 15% extra space above\n",
        "\n",
        "    # Add count labels on bars\n",
        "    for p in ax.patches:\n",
        "        height = int(p.get_height())\n",
        "        if height > 0:\n",
        "            ax.annotate(\n",
        "                f'{height}',\n",
        "                (p.get_x() + p.get_width() / 2., height),\n",
        "                ha='center', va='bottom',\n",
        "                fontsize=9, color='black', xytext=(0, 3),\n",
        "                textcoords='offset points'\n",
        "            )\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# House Grade Distribution\n",
        "plot_with_counts(house_final_test, \"House Bridge Grade Distribution\")\n",
        "\n",
        "# Senate Grade Distribution\n",
        "plot_with_counts(senate_final_test, \"Senate Bridge Grade Distribution\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Data Cleanup and Final Output Preparation**\n",
        "\n",
        "This section prepares the final datasets for export by cleaning up column names, creating standardized abbreviations, and organizing the data structure for maximum usability.\n",
        "\n",
        "### **Party Abbreviations**\n",
        "Convert full party names to standard abbreviations for consistency.\n",
        "\n",
        "### **State and District Formatting**\n",
        "Create standardized state abbreviations and district formatting for both House and Senate members.\n",
        "\n",
        "### **Column Reorganization**\n",
        "Reorganize columns in a logical order for final output, including all source data, normalized scores, and final results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create party abbreviations\n",
        "house_final_test[\"Party_Abbr\"] = house_final_test[\"Party\"].replace({\n",
        "    \"Republican\": \"R\",\n",
        "    \"Democratic\": \"D\",\n",
        "    \"Independent\": \"I\"\n",
        "})\n",
        "\n",
        "senate_final_test[\"Party_Abbr\"] = senate_final_test[\"Party\"].replace({\n",
        "    \"Republican\": \"R\",\n",
        "    \"Democratic\": \"D\",\n",
        "    \"Independent\": \"I\"\n",
        "})\n",
        "\n",
        "print(\"Party abbreviations created successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create state abbreviations mapping\n",
        "state_abbr = {\n",
        "    'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR', 'California': 'CA',\n",
        "    'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE', 'Florida': 'FL', 'Georgia': 'GA',\n",
        "    'Hawaii': 'HI', 'Idaho': 'ID', 'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA',\n",
        "    'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD',\n",
        "    'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS', 'Missouri': 'MO',\n",
        "    'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV', 'New Hampshire': 'NH', 'New Jersey': 'NJ',\n",
        "    'New Mexico': 'NM', 'New York': 'NY', 'North Carolina': 'NC', 'North Dakota': 'ND', 'Ohio': 'OH',\n",
        "    'Oklahoma': 'OK', 'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI', 'South Carolina': 'SC',\n",
        "    'South Dakota': 'SD', 'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT',\n",
        "    'Virginia': 'VA', 'Washington': 'WA', 'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY', \n",
        "    'District of Columbia': 'DC'\n",
        "}\n",
        "\n",
        "# Apply state abbreviations\n",
        "house_final_test['State_Abbr'] = house_final_test['State'].str.strip().map(state_abbr)\n",
        "senate_final_test['State_Abbr'] = senate_final_test['State'].str.strip().map(state_abbr)\n",
        "\n",
        "print(\"State abbreviations created successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create district formatting functions\n",
        "def make_sd(df, state_col, dist_col):\n",
        "    \"\"\"Create State-District format (e.g., 'CA-01')\"\"\"\n",
        "    # Convert district strings to numeric, default 1 for non-numeric (at-large)\n",
        "    dist_num = pd.to_numeric(df[dist_col], errors='coerce').fillna(1).replace(0, 1).astype(int)\n",
        "    # Zero-pad to two digits\n",
        "    dist_str = dist_num.apply(lambda d: f\"{d:02d}\")\n",
        "    return df[state_col].astype(str) + '-' + dist_str\n",
        "\n",
        "def make_sd_DW(df, state_col, dist_col):\n",
        "    \"\"\"Create StateDistrict format (e.g., 'CA01')\"\"\"\n",
        "    # Convert district strings to numeric, default 1 for non-numeric (at-large)\n",
        "    dist_num = pd.to_numeric(df[dist_col], errors='coerce').fillna(1).replace(0, 1).astype(int)\n",
        "    # Zero-pad to two digits\n",
        "    dist_str = dist_num.apply(lambda d: f\"{d:02d}\")\n",
        "    return df[state_col].astype(str) + dist_str\n",
        "\n",
        "# Apply district formatting to House\n",
        "house_final_test['District_Abbr'] = make_sd(house_final_test, 'State_Abbr', 'District')\n",
        "house_final_test['Dist_DW'] = make_sd_DW(house_final_test, 'State_Abbr', 'District')\n",
        "\n",
        "# Handle at-large states\n",
        "at_large_states = ['AK', 'DE', 'ND', 'SD', 'VT', 'WY']\n",
        "house_final_test.loc[house_final_test['State_Abbr'].isin(at_large_states), 'District_Abbr'] = \\\n",
        "    house_final_test['State_Abbr'] + '-AL'\n",
        "house_final_test.loc[house_final_test['State_Abbr'].isin(at_large_states), 'Dist_DW'] = \\\n",
        "    house_final_test['State_Abbr'] + '00'\n",
        "\n",
        "# Senate doesn't have districts\n",
        "senate_final_test['District_Abbr'] = np.nan\n",
        "senate_final_test['Dist_DW'] = np.nan\n",
        "\n",
        "print(\"District formatting completed successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reorganize columns in logical order\n",
        "column_order = [\n",
        "    'bioguide_id', 'Name', 'first_name', 'middle_name', 'last_name', 'nickname', \n",
        "    'Chamber', 'State', 'State_Abbr', 'District', 'District_Abbr', 'Dist_DW', \n",
        "    'Party', 'Party_Abbr', 'start_year', 'image_url',\n",
        "    'A: num_bills_with_cross_party_cosponsors', 'A_norm', 'A_weight',\n",
        "    'B: num_cross_party_cosponsored_bills', 'B_norm', 'B_weight',\n",
        "    'C: outcome_bipartisanship', 'C_norm', 'C_weight', \n",
        "    'D: outcome_bipartisanship_pct', 'D_norm', 'D_weight', \n",
        "    'E: attack_personal', 'E_norm', 'E_weight', \n",
        "    'F: attack_personal_pct', 'F_norm', 'F_weight', \n",
        "    'M: Cook PVI Raw', 'M_Cook_PVI_Cap', 'N: nominate_dim1', 'N_ideology_dist', 'P_flag',\n",
        "    'score_T', 'bonus_m', 'bonus_n', 'bonus_p', 'score_U', 'norm_U', 'Grade'\n",
        "]\n",
        "\n",
        "# Reorganize House data\n",
        "house_final_test = house_final_test[column_order]\n",
        "\n",
        "# Reorganize Senate data\n",
        "senate_final_test = senate_final_test[column_order]\n",
        "\n",
        "print(\"Column reorganization completed successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rename columns to final standardized names\n",
        "house_final_test.rename(columns={\n",
        "    'score_T': 'T_score', \n",
        "    'bonus_m': 'M_bonus', \n",
        "    'bonus_n': 'N_bonus', \n",
        "    'bonus_p': 'P_bonus',\n",
        "    'score_U': 'U_score', \n",
        "    'norm_U': 'Bridge_Score', \n",
        "    'Grade': 'Bridge_Grade',\n",
        "    'District_Abbr': 'Dist_abbr'\n",
        "}, inplace=True)\n",
        "\n",
        "senate_final_test.rename(columns={\n",
        "    'score_T': 'T_score', \n",
        "    'bonus_m': 'M_bonus', \n",
        "    'bonus_n': 'N_bonus', \n",
        "    'bonus_p': 'P_bonus',\n",
        "    'score_U': 'U_score', \n",
        "    'norm_U': 'Bridge_Score', \n",
        "    'Grade': 'Bridge_Grade',\n",
        "    'District_Abbr': 'Dist_abbr'\n",
        "}, inplace=True)\n",
        "\n",
        "print(\"Column renaming completed successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Export to Excel Files**\n",
        "\n",
        "This section exports the final datasets to Excel files in multiple formats for maximum flexibility and usability.\n",
        "\n",
        "### **Export Options**\n",
        "1. **Separate Files:** Individual Excel files for House and Senate\n",
        "2. **Combined with Separate Sheets:** Single Excel file with separate sheets for House and Senate\n",
        "3. **Combined Single Sheet:** Single Excel file with all data in one sheet\n",
        "\n",
        "All files include timestamps in the filename for version control.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Generate timestamp for file naming\n",
        "timestamp = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "# Export 1: Separate Excel files for House and Senate\n",
        "house_final_test.to_excel(f'house_scores_119_{timestamp}.xlsx', sheet_name='119 Grades', index=False)\n",
        "senate_final_test.to_excel(f'senate_scores_119_{timestamp}.xlsx', sheet_name='119 Grades', index=False)\n",
        "\n",
        "print(f\"✓ Separate files exported:\")\n",
        "print(f\"  - house_scores_119_{timestamp}.xlsx\")\n",
        "print(f\"  - senate_scores_119_{timestamp}.xlsx\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export 2: Combined file with separate sheets\n",
        "with pd.ExcelWriter(f'congress_scores_119_separate_sheets_{timestamp}.xlsx') as writer:\n",
        "    house_final_test.to_excel(writer, sheet_name='House', index=False)\n",
        "    senate_final_test.to_excel(writer, sheet_name='Senate', index=False)\n",
        "\n",
        "print(f\"✓ Combined file with separate sheets exported:\")\n",
        "print(f\"  - congress_scores_119_separate_sheets_{timestamp}.xlsx\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export 3: Combined file with single sheet\n",
        "congress_combined = pd.concat([house_final_test, senate_final_test])\n",
        "congress_combined.to_excel(f'congress_scores_119_single_sheet_{timestamp}.xlsx', sheet_name='119 Grades', index=False)\n",
        "\n",
        "print(f\"✓ Combined file with single sheet exported:\")\n",
        "print(f\"  - congress_scores_119_single_sheet_{timestamp}.xlsx\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
